# SigLIP: improved CLIP with sigmoid loss
# Stable training with larger batches

model_name: google/siglip-base-patch16-224
use_lora: true
loss_type: sigmoid

output_dir: experiments/output_siglip
epochs: 10
batch_size: 256
learning_rate: 1.0e-04

data_path: data/train.jsonl
val_data_path: data/val.jsonl
image_root: data/images
