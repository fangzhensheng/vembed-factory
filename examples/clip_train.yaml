# CLIP ViT-B/32 Training Configuration
# Complete standalone configuration for CLIP training

# Model Configuration
model_name_or_path: "openai/clip-vit-base-patch32"

# Training Configuration
use_lora: true
output_dir: experiments/output_clip
epochs: 20
batch_size: 128
learning_rate: 2.0e-5

# Data
data_path: data/train.jsonl
val_data_path: data/val.jsonl
image_root: data/images
