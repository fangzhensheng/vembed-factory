# CLIP ViT-B/32 Training Configuration

# --- Model ---
model_type: "clip"  # Base preset
use_lora: true

# --- Data ---
data_path: "data/train.jsonl"
val_data_path: "data/val.jsonl"
image_root: "data/images"

# --- Training ---
output_dir: "experiments/output_clip"
epochs: 20
batch_size: 128

