# DINOv2 + ColBERT for image-to-image retrieval on SOP
# Late-interaction loss with token-level embeddings

model_name: facebook/dinov2-base
retrieval_mode: i2i
use_lora: true

# ColBERT: MaxSim-based late-interaction scoring
# Requires token-level embeddings (no pooling) for per-token similarities
loss_type: colbert
pooling_method: none

# Attention-guided token pruning: keep top-32 patches by attention scores
# Reduces compute while preserving object-of-interest
topk_tokens: 32
projection_dim: 128

# Data
data_path: data/stanford_online_products/train.jsonl
val_data_path: data/stanford_online_products/val.jsonl
image_root: data/stanford_online_products
output_dir: experiments/output_sop_dinov2_colbert

# Training: 20 epochs with gradient caching for large batches
epochs: 20
batch_size: 128
eval_batch_size: 32
learning_rate: 1.0e-04
use_gradient_cache: true

# Logging
report_to: none
logging_steps: 10
save_steps: 1000
