# CLIP ViT-B/32 with Triplet loss
# Hard negative mining for improved ranking

model_name: openai/clip-vit-base-patch32
use_lora: true
loss_type: triplet

output_dir: experiments/output_clip_triplet
epochs: 5
batch_size: 128
learning_rate: 2.0e-5

data_path: data/train.jsonl
val_data_path: data/val.jsonl
image_root: data/images
