{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "source": [
    "# 3. Knowledge Distillation\n",
    "\n",
    "This notebook demonstrates how to distill knowledge from a large Teacher model into a smaller Student model.\n",
    "\n",
    "**Use Case:** Improving the performance of a small, efficient model (e.g., CLIP ViT-Base) by learning from a larger, more powerful model (e.g., CLIP ViT-Large).\n",
    "\n",
    "Ensure you have run `01_setup_and_data.ipynb` first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acae54e37e7d407bbb7b55eff062a284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Ensure we are in the project root\n",
    "if os.path.exists(\"vembed-factory\"):\n",
    "    os.chdir(\"vembed-factory\")\n",
    "elif not os.path.exists(\"run.py\"):\n",
    "    # Assume we are in notebooks dir\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "print(f\"Working Directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a63283cbaf04dbcab1f6479b197f3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config Data Paths\n",
    "if os.path.exists(\"data/flickr30k/train.jsonl\"):\n",
    "    DATA_PATH = \"data/flickr30k/train.jsonl\"\n",
    "    IMAGE_ROOT = \"data/flickr30k\"\n",
    "    VAL_DATA_PATH = \"data/flickr30k/val.jsonl\"\n",
    "else:\n",
    "    DATA_PATH = \"data/dummy/train.jsonl\"\n",
    "    IMAGE_ROOT = \"data/dummy\"\n",
    "    VAL_DATA_PATH = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd0d8092fe74a7c96281538738b07e2",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "- **Teacher**: `openai/clip-vit-large-patch14` (Frozen)\n",
    "- **Student**: `openai/clip-vit-base-patch32` (Trainable)\n",
    "- **Method**: Relation Distillation (KL Divergence on Similarity Matrices)\n",
    "- **Alpha**: 0.5 (50% Task Loss, 50% Distillation Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eea5119410473aa328ad9291626812",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEACHER_MODEL = \"openai/clip-vit-large-patch14\"\n",
    "STUDENT_MODEL = \"openai/clip-vit-base-patch32\"\n",
    "\n",
    "print(f\"Teacher: {TEACHER_MODEL}\")\n",
    "print(f\"Student: {STUDENT_MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edb47106e1a46a883d545849b8ab81b",
   "metadata": {},
   "source": [
    "## Start Distillation Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10185d26023b46108eb7d9f57d49d2b3",
   "metadata": {},
   "outputs": [],
   "source": "!python run.py examples/clip_train.yaml \\\n    --data_path $DATA_PATH \\\n    --val_data_path \"$VAL_DATA_PATH\" \\\n    --image_root \"$IMAGE_ROOT\" \\\n    --config_override \\\n        output_dir=output_distill \\\n        epochs=3 \\\n        batch_size=32 \\\n        use_mrl=true \\\n        model_name=\"$STUDENT_MODEL\" \\\n        teacher_model_name=\"$TEACHER_MODEL\" \\\n        distillation_alpha=0.5 \\\n        distillation_temperature=2.0 \\\n        distillation_loss_type=\"kl\""
  },
  {
   "cell_type": "markdown",
   "id": "8763a12b2bbd4a93a75aff182afb95dc",
   "metadata": {},
   "source": [
    "## Evaluation Comparison\n",
    "Compare the distilled model against the standard fine-tuned model (if available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7623eae2785240b9bd12b16a66d81610",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(VAL_DATA_PATH):\n",
    "    print(\"Evaluating Distilled Model...\")\n",
    "    !python scripts/evaluate_simple.py \\\n",
    "        --model_path output_distill/checkpoint-epoch-3 \\\n",
    "        --data_path $VAL_DATA_PATH \\\n",
    "        --image_root $IMAGE_ROOT \\\n",
    "        --output_dir eval_results_distill\n",
    "\n",
    "    !cat eval_results_distill/evaluation_report.md"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}